#研究数据
#数据集包含以下列：
#学生GPA（成绩）
#GRE考试成绩（考试）
#级别（1-4）
import pandas as pd
data=pd.rad_csv("http://www.ats.ucla.edu/stat/data/binary.csv")
print(data)
#在这里可以看到第一列是标签y它对应于接受、拒绝。即标签1表示学生被录取，标签0表示学生不被录取
#预处理数据
#看起来的情况是学生的成绩越好，越有可能被录取。等级与此有关。所以要做的是，对排名等级进行一次性彪马，6个输入变量是：
#考试（GPA）
#成绩（GRE）
#等级1
#等级2
#等级3
#等级4
#最后4个输入僵尸二进制变量，如果学生具有该等级，则其值为1，否则为0
#首先要注意的是，考试分数的范围是800.而成绩范围是4，这是一个巨大的差异。这会影响我们的训练，通常情况下，
#最好的办法是将分数归一化，使其在0和1之间，我们可以这样做：
data["gre"]=data["gre"]/800
data["gpa"]=data["gpa"]/4
#现在，将数据输入分成X和标签y,并对输出进行one-hot编码，因此它显示为两类（录取和不录取）
X=np.array(data)[:,1:]
y=np_utils.to_categorical(np.array(data["admit"]))
#构建模型架构
#最后，定义模型架构，可以使用不同的架构，不过这里有个例子
model=Sequential()
model.add(Dense(128,input_dim=6))
model.add(Activation("sigmoid"))
model.add(Dense(32))
model.add(Acitvation("sigmoid"))
model.add(Dense(2))
model.add(Activation("sigmoid"))
model.compile(loss="categorical_crossentropy",optimizer="adam",metrics=["accuracy"])
model.summary()
#categorical_crossentropy会给出错误函数，一直在使用，但还有其他选项。有几个优化器可供你选择，以改善你的训练。在这里我们使用adam
#但是像rmsprop也很有用，他们使用了我们在下面的课程中介绍的各种技巧
#训练模型
#现在，我们用1000个epho训练模型，不用担心遇到batch_size我们很快就会学到它
model.fit(X_train,y_train,epochs=1000,batch_size=100,vebose=0)
#评估模型
score=model.evaluate(X_train,y_train)
#结果可能会有不同，但是你应可以获得超过70%的准确度，现在你已经训练了你的第一个神经网络来分析一个数据集
